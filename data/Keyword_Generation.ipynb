{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "appended_data = []\n",
    "\n",
    "for file in glob.glob('/Users/zhongxur/Desktop/EE599/AOL-user-ct-collection/data_full/*.txt'):\n",
    "    Single_txt = pd.read_csv(file,delimiter=\"\\t\")\n",
    "    appended_data.append(Single_txt)\n",
    "    \n",
    "data_full = pd.concat(appended_data)\n",
    "\n",
    "\n",
    "data_full.to_csv('Full_data.csv')\n",
    "\n",
    "v = data_full.AnonID.value_counts()\n",
    "Data_100 = data_full[data_full.AnonID.isin(v.index[v.gt(100)])]\n",
    "\n",
    "\n",
    "Data_100.to_csv('data_100Entry.csv')\n",
    "\n",
    "# data_filtered['Query'] = str(data_filtered['Query'])\n",
    "\n",
    "Cancer_key = pd.read_csv('/Users/zhongxur/Desktop/EE599/AOL-user-ct-collection/Cancer_Keywords.csv')\n",
    "\n",
    "Alcohol_key =pd.read_csv('/Users/zhongxur/Desktop/EE599/AOL-user-ct-collection/Alcoholic_Keywords.csv')\n",
    "\n",
    "Pregnancy_key = pd.read_csv('/Users/zhongxur/Desktop/EE599/AOL-user-ct-collection/Pregnant_Keywords.csv')\n",
    "\n",
    "Keywords = pd.concat([Cancer_key,Alcohol_key])\n",
    "Keywords = pd.concat([Keywords,Pregnancy_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    " \n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    " \n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.144*\"form\" + 0.112*\"patient\" + 0.112*\"introduct\" + 0.081*\"address\" + 0.081*\"fact\" + 0.049*\"sit\" + 0.049*\"leukemia\" + 0.002*\"site\" + 0.002*\"definit\" + 0.002*\"info\"\n",
      "Topic: 1 \n",
      "Words: 0.181*\"diagnosi\" + 0.051*\"articl\" + 0.051*\"process\" + 0.051*\"tropic\" + 0.051*\"paragraph\" + 0.051*\"colon\" + 0.051*\"search\" + 0.051*\"prevent\" + 0.034*\"statist\" + 0.018*\"care\"\n",
      "Topic: 2 \n",
      "Words: 0.100*\"stag\" + 0.100*\"donat\" + 0.075*\"name\" + 0.038*\"british\" + 0.038*\"magazin\" + 0.038*\"sick\" + 0.038*\"unit\" + 0.038*\"recurr\" + 0.038*\"pathophysiolog\" + 0.038*\"growth\"\n",
      "Topic: 3 \n",
      "Words: 0.114*\"oncolog\" + 0.086*\"site\" + 0.072*\"كونكر\" + 0.044*\"impact\" + 0.044*\"characterist\" + 0.044*\"factor\" + 0.044*\"offici\" + 0.044*\"ribbon\" + 0.044*\"pink\" + 0.044*\"bodi\"\n",
      "Topic: 4 \n",
      "Words: 0.092*\"prevent\" + 0.092*\"news\" + 0.092*\"skin\" + 0.056*\"basic\" + 0.056*\"jewelri\" + 0.056*\"gift\" + 0.056*\"tratamiento\" + 0.056*\"page\" + 0.020*\"walk\" + 0.003*\"stage\"\n",
      "Topic: 5 \n",
      "Words: 0.091*\"site\" + 0.076*\"rat\" + 0.076*\"articl\" + 0.046*\"discuss\" + 0.046*\"small\" + 0.046*\"compani\" + 0.046*\"prostata\" + 0.046*\"occur\" + 0.046*\"surviv\" + 0.046*\"note\"\n",
      "Topic: 6 \n",
      "Words: 0.142*\"info\" + 0.044*\"inflammatori\" + 0.044*\"recoveri\" + 0.044*\"best\" + 0.044*\"telephon\" + 0.044*\"bring\" + 0.044*\"effect\" + 0.044*\"explan\" + 0.044*\"wig\" + 0.044*\"lobular\"\n",
      "Topic: 7 \n",
      "Words: 0.162*\"statist\" + 0.050*\"anticanc\" + 0.050*\"food\" + 0.050*\"explain\" + 0.050*\"colon\" + 0.050*\"skin\" + 0.050*\"fight\" + 0.050*\"tumour\" + 0.050*\"stag\" + 0.050*\"public\"\n",
      "Topic: 8 \n",
      "Words: 0.133*\"what\" + 0.089*\"surgeri\" + 0.075*\"vaccin\" + 0.046*\"cervic\" + 0.046*\"colon\" + 0.046*\"curabl\" + 0.046*\"diagnos\" + 0.046*\"anal\" + 0.046*\"organis\" + 0.046*\"cáncer\"\n",
      "Topic: 9 \n",
      "Words: 0.094*\"السرطان\" + 0.094*\"general\" + 0.094*\"group\" + 0.057*\"present\" + 0.057*\"detail\" + 0.057*\"cançar\" + 0.021*\"prevent\" + 0.021*\"donat\" + 0.021*\"stag\" + 0.021*\"stage\"\n",
      "Topic: 10 \n",
      "Words: 0.122*\"symbol\" + 0.122*\"intern\" + 0.077*\"sign\" + 0.047*\"aicr\" + 0.047*\"learn\" + 0.047*\"metastat\" + 0.047*\"histori\" + 0.047*\"کانسر\" + 0.047*\"câncer\" + 0.017*\"rat\"\n",
      "Topic: 11 \n",
      "Words: 0.124*\"definit\" + 0.075*\"prognosi\" + 0.075*\"curabl\" + 0.038*\"exampl\" + 0.038*\"quimioterapia\" + 0.038*\"phone\" + 0.038*\"liver\" + 0.038*\"medic\" + 0.038*\"sein\" + 0.038*\"heart\"\n",
      "Topic: 12 \n",
      "Words: 0.108*\"ill\" + 0.091*\"british\" + 0.091*\"disord\" + 0.055*\"herbal\" + 0.055*\"canc\" + 0.055*\"sarcoma\" + 0.055*\"read\" + 0.055*\"gemini\" + 0.020*\"info\" + 0.003*\"site\"\n",
      "Topic: 13 \n",
      "Words: 0.092*\"list\" + 0.092*\"imag\" + 0.047*\"rate\" + 0.047*\"pulmonar\" + 0.047*\"unit\" + 0.047*\"address\" + 0.047*\"effect\" + 0.047*\"council\" + 0.047*\"pictur\" + 0.047*\"surviv\"\n",
      "Topic: 14 \n",
      "Words: 0.098*\"bracelet\" + 0.078*\"survivor\" + 0.060*\"censer\" + 0.060*\"mean\" + 0.060*\"carcinoma\" + 0.060*\"trial\" + 0.060*\"clinic\" + 0.060*\"adenocarcinoma\" + 0.021*\"intern\" + 0.003*\"stage\"\n",
      "Topic: 15 \n",
      "Words: 0.170*\"stage\" + 0.058*\"viral\" + 0.058*\"pisci\" + 0.058*\"anderson\" + 0.058*\"affect\" + 0.058*\"york\" + 0.040*\"survivor\" + 0.021*\"definit\" + 0.021*\"introduct\" + 0.021*\"termin\"\n",
      "Topic: 16 \n",
      "Words: 0.151*\"termin\" + 0.096*\"help\" + 0.058*\"colorect\" + 0.058*\"neoplasm\" + 0.058*\"therapi\" + 0.058*\"test\" + 0.058*\"descript\" + 0.021*\"diagnosi\" + 0.003*\"present\" + 0.003*\"canc\"\n",
      "Topic: 17 \n",
      "Words: 0.099*\"walk\" + 0.099*\"month\" + 0.061*\"note\" + 0.061*\"radiotherapi\" + 0.061*\"chemo\" + 0.061*\"fact\" + 0.061*\"screen\" + 0.022*\"definit\" + 0.022*\"oncolog\" + 0.003*\"diagnosi\"\n",
      "Topic: 18 \n",
      "Words: 0.130*\"altern\" + 0.082*\"cancel\" + 0.050*\"incid\" + 0.050*\"risk\" + 0.050*\"mama\" + 0.050*\"male\" + 0.050*\"option\" + 0.050*\"note\" + 0.050*\"short\" + 0.018*\"skin\"\n",
      "Topic: 19 \n",
      "Words: 0.122*\"care\" + 0.104*\"diet\" + 0.104*\"advanc\" + 0.053*\"ribbon\" + 0.053*\"canadian\" + 0.053*\"macmillan\" + 0.053*\"english\" + 0.053*\"sourc\" + 0.003*\"stag\" + 0.003*\"stage\"\n"
     ]
    }
   ],
   "source": [
    "documents = Cancer_key['Keyword']\n",
    "\n",
    "\n",
    "processed_docs = documents.map(preprocess)\n",
    "processed_docs[:10]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.01, keep_n=1000)\n",
    "len(dictionary)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "bow_doc_0 = bow_corpus[0]\n",
    "for i in range(len(bow_doc_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], \n",
    "                                               dictionary[bow_doc_0[i][0]], \n",
    "bow_doc_0[i][1]))\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.212*\"type\" + 0.053*\"differ\" + 0.049*\"symptom\" + 0.045*\"tumor\" + 0.041*\"malign\" + 0.034*\"breast\" + 0.033*\"lung\" + 0.032*\"site\" + 0.026*\"treatment\" + 0.019*\"altern\"\n",
      "Topic: 1 Word: 0.093*\"organ\" + 0.046*\"human\" + 0.039*\"awar\" + 0.037*\"breast\" + 0.037*\"oncolog\" + 0.031*\"note\" + 0.029*\"research\" + 0.028*\"american\" + 0.023*\"chariti\" + 0.022*\"short\"\n",
      "Topic: 2 Word: 0.128*\"research\" + 0.087*\"institut\" + 0.060*\"nation\" + 0.047*\"inform\" + 0.040*\"websit\" + 0.039*\"number\" + 0.029*\"general\" + 0.025*\"support\" + 0.024*\"breast\" + 0.022*\"lung\"\n",
      "Topic: 3 Word: 0.071*\"societi\" + 0.056*\"foundat\" + 0.040*\"breast\" + 0.038*\"statist\" + 0.038*\"chariti\" + 0.031*\"ill\" + 0.027*\"sign\" + 0.023*\"symptom\" + 0.020*\"american\" + 0.019*\"inform\"\n",
      "Topic: 4 Word: 0.055*\"stage\" + 0.043*\"breast\" + 0.041*\"cell\" + 0.041*\"termin\" + 0.040*\"kind\" + 0.029*\"stag\" + 0.029*\"name\" + 0.029*\"cancel\" + 0.025*\"month\" + 0.025*\"diseas\"\n",
      "Topic: 5 Word: 0.136*\"diseas\" + 0.044*\"center\" + 0.042*\"wikipedia\" + 0.035*\"differ\" + 0.032*\"kind\" + 0.031*\"type\" + 0.028*\"research\" + 0.026*\"donat\" + 0.025*\"intern\" + 0.024*\"america\"\n",
      "Topic: 6 Word: 0.114*\"breast\" + 0.080*\"caus\" + 0.050*\"form\" + 0.050*\"info\" + 0.027*\"type\" + 0.025*\"news\" + 0.024*\"websit\" + 0.022*\"care\" + 0.022*\"diseas\" + 0.018*\"british\"\n",
      "Topic: 7 Word: 0.110*\"logo\" + 0.037*\"research\" + 0.036*\"articl\" + 0.034*\"what\" + 0.033*\"breast\" + 0.032*\"caus\" + 0.031*\"bracelet\" + 0.028*\"symptom\" + 0.026*\"prevent\" + 0.026*\"prostat\"\n",
      "Topic: 8 Word: 0.047*\"definit\" + 0.044*\"fact\" + 0.043*\"introduct\" + 0.037*\"skin\" + 0.036*\"support\" + 0.031*\"stag\" + 0.029*\"effect\" + 0.027*\"cell\" + 0.024*\"institut\" + 0.022*\"caus\"\n",
      "Topic: 9 Word: 0.097*\"treatment\" + 0.055*\"america\" + 0.037*\"breast\" + 0.036*\"diagnosi\" + 0.034*\"radiat\" + 0.031*\"patient\" + 0.031*\"associ\" + 0.028*\"السرطان\" + 0.027*\"walk\" + 0.026*\"center\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    " \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.142*\"healthi\" + 0.142*\"want\" + 0.120*\"morn\" + 0.120*\"sick\" + 0.120*\"relat\" + 0.075*\"help\" + 0.029*\"educ\" + 0.007*\"ladi\" + 0.007*\"second\" + 0.007*\"miscarriag\"\n",
      "Topic: 1 \n",
      "Words: 0.146*\"quick\" + 0.146*\"pictur\" + 0.146*\"period\" + 0.123*\"prenat\" + 0.123*\"second\" + 0.030*\"mother\" + 0.030*\"weight\" + 0.007*\"miscarriag\" + 0.007*\"ladi\" + 0.007*\"natur\"\n",
      "Topic: 2 \n",
      "Words: 0.226*\"fact\" + 0.202*\"plan\" + 0.080*\"miscarriag\" + 0.080*\"second\" + 0.080*\"help\" + 0.031*\"prenat\" + 0.031*\"diabet\" + 0.007*\"natur\" + 0.007*\"video\" + 0.007*\"cycl\"\n",
      "Topic: 3 \n",
      "Words: 0.169*\"mother\" + 0.128*\"labor\" + 0.128*\"fast\" + 0.128*\"detail\" + 0.108*\"deliveri\" + 0.067*\"sit\" + 0.026*\"chanc\" + 0.026*\"effect\" + 0.006*\"prenat\" + 0.006*\"natur\"\n",
      "Topic: 4 \n",
      "Words: 0.250*\"step\" + 0.197*\"natur\" + 0.143*\"diabet\" + 0.089*\"troubl\" + 0.008*\"miscarriag\" + 0.008*\"second\" + 0.008*\"cycl\" + 0.008*\"plan\" + 0.008*\"ladi\" + 0.008*\"stag\"\n",
      "Topic: 5 \n",
      "Words: 0.139*\"matern\" + 0.118*\"tri\" + 0.118*\"ladi\" + 0.118*\"risk\" + 0.118*\"educ\" + 0.118*\"effect\" + 0.028*\"common\" + 0.007*\"second\" + 0.007*\"prenat\" + 0.007*\"natur\"\n",
      "Topic: 6 \n",
      "Words: 0.201*\"video\" + 0.136*\"problem\" + 0.136*\"femal\" + 0.115*\"chanc\" + 0.071*\"prenat\" + 0.071*\"sit\" + 0.028*\"cycl\" + 0.006*\"natur\" + 0.006*\"miscarriag\" + 0.006*\"second\"\n",
      "Topic: 7 \n",
      "Words: 0.210*\"stag\" + 0.188*\"weight\" + 0.143*\"gain\" + 0.077*\"mom\" + 0.029*\"miscarriag\" + 0.029*\"expect\" + 0.029*\"natur\" + 0.029*\"risk\" + 0.029*\"deliveri\" + 0.007*\"prenat\"\n",
      "Topic: 8 \n",
      "Words: 0.154*\"have\" + 0.154*\"chart\" + 0.130*\"miscarriag\" + 0.080*\"troubl\" + 0.078*\"mom\" + 0.031*\"second\" + 0.031*\"ladi\" + 0.031*\"sick\" + 0.031*\"morn\" + 0.031*\"plan\"\n",
      "Topic: 9 \n",
      "Words: 0.180*\"cycl\" + 0.180*\"common\" + 0.136*\"develop\" + 0.115*\"expect\" + 0.071*\"ladi\" + 0.028*\"tri\" + 0.028*\"natur\" + 0.028*\"relat\" + 0.006*\"prenat\" + 0.006*\"second\"\n"
     ]
    }
   ],
   "source": [
    "documents = Pregnancy_key['Keyword']\n",
    "\n",
    "\n",
    "processed_docs = documents.map(preprocess)\n",
    "processed_docs[:10]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.01, keep_n=1000)\n",
    "len(dictionary)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "bow_doc_0 = bow_corpus[0]\n",
    "for i in range(len(bow_doc_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], \n",
    "                                               dictionary[bow_doc_0[i][0]], \n",
    "bow_doc_0[i][1]))\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.085*\"common\" + 0.084*\"get\" + 0.080*\"video\" + 0.064*\"inform\" + 0.058*\"childbirth\" + 0.051*\"quick\" + 0.048*\"educ\" + 0.048*\"relat\" + 0.044*\"risk\" + 0.042*\"mom\"\n",
      "Topic: 1 Word: 0.119*\"best\" + 0.108*\"fertil\" + 0.104*\"woman\" + 0.068*\"plan\" + 0.061*\"help\" + 0.058*\"possibl\" + 0.053*\"earliest\" + 0.041*\"tri\" + 0.032*\"cycl\" + 0.029*\"diet\"\n",
      "Topic: 2 Word: 0.119*\"trimest\" + 0.116*\"month\" + 0.102*\"preg\" + 0.095*\"calendar\" + 0.073*\"miscarriag\" + 0.072*\"calcul\" + 0.055*\"earliest\" + 0.052*\"matern\" + 0.040*\"fertil\" + 0.037*\"stage\"\n",
      "Topic: 3 Word: 0.120*\"women\" + 0.107*\"class\" + 0.070*\"childbirth\" + 0.068*\"ladi\" + 0.066*\"natur\" + 0.061*\"inform\" + 0.051*\"websit\" + 0.050*\"detail\" + 0.049*\"mother\" + 0.030*\"infertil\"\n",
      "Topic: 4 Word: 0.202*\"birth\" + 0.122*\"stage\" + 0.079*\"weight\" + 0.074*\"develop\" + 0.047*\"gain\" + 0.039*\"chanc\" + 0.039*\"healthi\" + 0.032*\"plan\" + 0.027*\"risk\" + 0.015*\"exercis\"\n",
      "Topic: 5 Word: 0.156*\"date\" + 0.139*\"get\" + 0.083*\"calcul\" + 0.058*\"fast\" + 0.055*\"babi\" + 0.051*\"have\" + 0.042*\"troubl\" + 0.038*\"class\" + 0.036*\"diet\" + 0.036*\"birth\"\n",
      "Topic: 6 Word: 0.129*\"woman\" + 0.087*\"diabet\" + 0.087*\"possibl\" + 0.080*\"problem\" + 0.075*\"deliveri\" + 0.060*\"expect\" + 0.041*\"get\" + 0.036*\"healthi\" + 0.034*\"labor\" + 0.031*\"diet\"\n",
      "Topic: 7 Word: 0.262*\"inform\" + 0.123*\"infertil\" + 0.103*\"conceiv\" + 0.084*\"websit\" + 0.083*\"test\" + 0.053*\"pictur\" + 0.033*\"chart\" + 0.026*\"tri\" + 0.013*\"natur\" + 0.011*\"troubl\"\n",
      "Topic: 8 Word: 0.084*\"concept\" + 0.083*\"doula\" + 0.069*\"earliest\" + 0.069*\"period\" + 0.069*\"step\" + 0.069*\"want\" + 0.064*\"prenat\" + 0.060*\"sit\" + 0.055*\"calcul\" + 0.046*\"date\"\n",
      "Topic: 9 Word: 0.157*\"babi\" + 0.117*\"ovul\" + 0.100*\"exercis\" + 0.081*\"stag\" + 0.081*\"fact\" + 0.064*\"effect\" + 0.057*\"cycl\" + 0.035*\"birth\" + 0.027*\"women\" + 0.014*\"calendar\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    " \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.249*\"quiz\" + 0.249*\"articl\" + 0.140*\"high\" + 0.140*\"statist\" + 0.031*\"program\" + 0.004*\"classifi\" + 0.004*\"harm\" + 0.004*\"drinker\" + 0.004*\"peopl\" + 0.004*\"constitut\"\n",
      "Topic: 1 \n",
      "Words: 0.277*\"test\" + 0.238*\"support\" + 0.200*\"teenag\" + 0.006*\"physic\" + 0.006*\"program\" + 0.006*\"clinic\" + 0.006*\"articl\" + 0.006*\"high\" + 0.006*\"peopl\" + 0.006*\"bodi\"\n",
      "Topic: 2 \n",
      "Words: 0.173*\"poison\" + 0.173*\"drug\" + 0.173*\"common\" + 0.173*\"treat\" + 0.039*\"etoh\" + 0.039*\"alchol\" + 0.005*\"high\" + 0.005*\"clinic\" + 0.005*\"peopl\" + 0.005*\"classifi\"\n",
      "Topic: 3 \n",
      "Words: 0.309*\"alchol\" + 0.157*\"think\" + 0.096*\"articl\" + 0.096*\"classifi\" + 0.035*\"rehabilit\" + 0.035*\"constitut\" + 0.035*\"everyday\" + 0.035*\"drug\" + 0.005*\"issu\" + 0.005*\"program\"\n",
      "Topic: 4 \n",
      "Words: 0.346*\"disord\" + 0.065*\"center\" + 0.065*\"constitut\" + 0.065*\"bodi\" + 0.065*\"substanc\" + 0.008*\"articl\" + 0.008*\"clinic\" + 0.008*\"peopl\" + 0.008*\"danger\" + 0.008*\"inform\"\n",
      "Topic: 5 \n",
      "Words: 0.362*\"sever\" + 0.167*\"determin\" + 0.102*\"stori\" + 0.102*\"disord\" + 0.037*\"peopl\" + 0.005*\"consequ\" + 0.005*\"drinker\" + 0.005*\"clinic\" + 0.005*\"constitut\" + 0.005*\"prevent\"\n",
      "Topic: 6 \n",
      "Words: 0.216*\"ethanol\" + 0.132*\"term\" + 0.132*\"constitut\" + 0.132*\"medic\" + 0.048*\"peopl\" + 0.048*\"inform\" + 0.006*\"articl\" + 0.006*\"clinic\" + 0.006*\"program\" + 0.006*\"physic\"\n",
      "Topic: 7 \n",
      "Words: 0.224*\"issu\" + 0.224*\"constitut\" + 0.224*\"peopl\" + 0.070*\"physic\" + 0.036*\"diseas\" + 0.005*\"addict\" + 0.005*\"program\" + 0.005*\"articl\" + 0.005*\"alchol\" + 0.005*\"drug\"\n",
      "Topic: 8 \n",
      "Words: 0.295*\"clinic\" + 0.216*\"substanc\" + 0.163*\"pictur\" + 0.030*\"explain\" + 0.030*\"test\" + 0.030*\"free\" + 0.030*\"treat\" + 0.030*\"think\" + 0.004*\"danger\" + 0.004*\"articl\"\n",
      "Topic: 9 \n",
      "Words: 0.293*\"addict\" + 0.185*\"explain\" + 0.113*\"stori\" + 0.113*\"drug\" + 0.041*\"sever\" + 0.005*\"program\" + 0.005*\"articl\" + 0.005*\"clinic\" + 0.005*\"danger\" + 0.005*\"peopl\"\n",
      "Topic: 10 \n",
      "Words: 0.355*\"consequ\" + 0.200*\"awar\" + 0.122*\"relat\" + 0.045*\"program\" + 0.006*\"articl\" + 0.006*\"sever\" + 0.006*\"clinic\" + 0.006*\"peopl\" + 0.006*\"danger\" + 0.006*\"addict\"\n",
      "Topic: 11 \n",
      "Words: 0.248*\"bodi\" + 0.157*\"what\" + 0.157*\"step\" + 0.096*\"christian\" + 0.035*\"poison\" + 0.035*\"articl\" + 0.035*\"classifi\" + 0.035*\"common\" + 0.005*\"constitut\" + 0.005*\"treat\"\n",
      "Topic: 12 \n",
      "Words: 0.281*\"danger\" + 0.205*\"fact\" + 0.178*\"physic\" + 0.029*\"test\" + 0.029*\"ethanol\" + 0.029*\"prevent\" + 0.029*\"addict\" + 0.029*\"high\" + 0.029*\"teenag\" + 0.004*\"clinic\"\n",
      "Topic: 13 \n",
      "Words: 0.270*\"center\" + 0.149*\"harm\" + 0.149*\"treat\" + 0.076*\"christian\" + 0.041*\"rehabilit\" + 0.028*\"what\" + 0.028*\"issu\" + 0.028*\"qualifi\" + 0.028*\"articl\" + 0.028*\"clinic\"\n",
      "Topic: 14 \n",
      "Words: 0.396*\"rehabilit\" + 0.212*\"drug\" + 0.047*\"drinker\" + 0.047*\"alchol\" + 0.006*\"issu\" + 0.006*\"program\" + 0.006*\"articl\" + 0.006*\"clinic\" + 0.006*\"danger\" + 0.006*\"physic\"\n",
      "Topic: 15 \n",
      "Words: 0.019*\"center\" + 0.019*\"program\" + 0.019*\"articl\" + 0.019*\"sever\" + 0.019*\"peopl\" + 0.019*\"danger\" + 0.019*\"classifi\" + 0.019*\"rehabilit\" + 0.019*\"addict\" + 0.019*\"constitut\"\n",
      "Topic: 16 \n",
      "Words: 0.185*\"free\" + 0.185*\"classifi\" + 0.185*\"medic\" + 0.113*\"term\" + 0.041*\"danger\" + 0.041*\"drug\" + 0.005*\"addict\" + 0.005*\"qualifi\" + 0.005*\"peopl\" + 0.005*\"alchol\"\n",
      "Topic: 17 \n",
      "Words: 0.392*\"etoh\" + 0.248*\"prevent\" + 0.007*\"program\" + 0.007*\"articl\" + 0.007*\"constitut\" + 0.007*\"clinic\" + 0.007*\"peopl\" + 0.007*\"treat\" + 0.007*\"alchol\" + 0.007*\"everyday\"\n",
      "Topic: 18 \n",
      "Words: 0.200*\"everyday\" + 0.200*\"program\" + 0.160*\"inform\" + 0.160*\"diseas\" + 0.062*\"relat\" + 0.023*\"determin\" + 0.023*\"awar\" + 0.023*\"articl\" + 0.023*\"fact\" + 0.003*\"drinker\"\n",
      "Topic: 19 \n",
      "Words: 0.241*\"drinker\" + 0.241*\"qualifi\" + 0.182*\"need\" + 0.034*\"medic\" + 0.034*\"issu\" + 0.034*\"everyday\" + 0.034*\"step\" + 0.004*\"rehabilit\" + 0.004*\"program\" + 0.004*\"classifi\"\n"
     ]
    }
   ],
   "source": [
    "documents = Alcohol_key['Keyword']\n",
    "\n",
    "\n",
    "processed_docs = documents.map(preprocess)\n",
    "processed_docs[:10]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "\n",
    "\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.01, keep_n=1000)\n",
    "len(dictionary)\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "bow_doc_0 = bow_corpus[0]\n",
    "for i in range(len(bow_doc_0)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_0[i][0], \n",
    "                                               dictionary[bow_doc_0[i][0]], \n",
    "bow_doc_0[i][1]))\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "\n",
    "\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=20, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.224*\"sign\" + 0.099*\"excess\" + 0.098*\"consumpt\" + 0.061*\"symptom\" + 0.055*\"chronic\" + 0.050*\"consid\" + 0.042*\"treat\" + 0.035*\"medic\" + 0.034*\"test\" + 0.029*\"awar\"\n",
      "Topic: 1 Word: 0.172*\"definit\" + 0.131*\"make\" + 0.098*\"anonym\" + 0.094*\"quit\" + 0.055*\"clinic\" + 0.050*\"drink\" + 0.046*\"inform\" + 0.035*\"function\" + 0.020*\"depend\" + 0.020*\"treatment\"\n",
      "Topic: 2 Word: 0.168*\"depend\" + 0.122*\"symptom\" + 0.105*\"help\" + 0.104*\"know\" + 0.056*\"program\" + 0.042*\"physic\" + 0.041*\"sever\" + 0.037*\"rehabilit\" + 0.035*\"center\" + 0.031*\"abus\"\n",
      "Topic: 3 Word: 0.137*\"stop\" + 0.104*\"health\" + 0.063*\"danger\" + 0.063*\"abus\" + 0.052*\"substanc\" + 0.049*\"diseas\" + 0.047*\"drink\" + 0.042*\"what\" + 0.038*\"relat\" + 0.037*\"support\"\n",
      "Topic: 4 Word: 0.229*\"abus\" + 0.166*\"consid\" + 0.094*\"defin\" + 0.072*\"treatment\" + 0.046*\"drug\" + 0.044*\"person\" + 0.039*\"consequ\" + 0.036*\"etoh\" + 0.035*\"caus\" + 0.027*\"stori\"\n",
      "Topic: 5 Word: 0.325*\"drink\" + 0.104*\"abus\" + 0.076*\"tell\" + 0.047*\"make\" + 0.044*\"problem\" + 0.042*\"definit\" + 0.034*\"addict\" + 0.030*\"bodi\" + 0.029*\"heavi\" + 0.027*\"help\"\n",
      "Topic: 6 Word: 0.170*\"person\" + 0.158*\"mean\" + 0.077*\"qualifi\" + 0.055*\"disord\" + 0.044*\"drink\" + 0.041*\"common\" + 0.039*\"ethanol\" + 0.039*\"effect\" + 0.038*\"term\" + 0.027*\"symptom\"\n",
      "Topic: 7 Word: 0.160*\"caus\" + 0.159*\"drink\" + 0.093*\"symptom\" + 0.071*\"sign\" + 0.059*\"constitut\" + 0.057*\"everyday\" + 0.050*\"peopl\" + 0.033*\"health\" + 0.027*\"harm\" + 0.026*\"effect\"\n",
      "Topic: 8 Word: 0.301*\"problem\" + 0.088*\"drink\" + 0.081*\"bing\" + 0.077*\"alchol\" + 0.042*\"sign\" + 0.038*\"issu\" + 0.031*\"stop\" + 0.030*\"determin\" + 0.028*\"quiz\" + 0.024*\"step\"\n",
      "Topic: 9 Word: 0.250*\"rehab\" + 0.161*\"effect\" + 0.084*\"articl\" + 0.068*\"classifi\" + 0.053*\"drinker\" + 0.050*\"problem\" + 0.044*\"drink\" + 0.026*\"abus\" + 0.021*\"free\" + 0.018*\"determin\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    " \n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
